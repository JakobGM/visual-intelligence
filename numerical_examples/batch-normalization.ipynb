{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem occuring when training deep neural networks is internal covariate shift; When a network learns its covariates it uses a optimization algorithm on a given loss function. When the covariates in one layer then is changed by this method it affects the other layers, and it needs to relearn its parameters to account for this shift in covariates.<a href = \"https://arxiv.org/pdf/1502.03167v3.pdf\"> **Sergey Ioffe and Christian Szegedy**</a> proposed a method to account for this *internal covariate shift*, called *batch normazation*.\n",
    "\n",
    "We will in this numerical example present the algorithm of batch normalization and how it is implemented in a neural network, and show some results from the initial paper. We will also create our own code that will apply this algorithm to mini-batches on a given kernel and activiation function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal Covariance Shift\n",
    "\n",
    "Given a loss function the covariates of a network $\\theta$ is found from a optmization method \n",
    "\\begin{equation*}\n",
    "\\theta = \\underset{\\theta}{\\mathrm{argmin}}\\frac{1}{N}\\sum\\limits_{i=1}^N \\mathcal{l}(x_i,\\theta),\n",
    "\\end{equation*}\n",
    "where $x_i$ is the input data that the network is trained on and $\\mathcal{l}$ is the loss function that is to be minimized.\n",
    "\n",
    "Lets say we have a network of two layers with each a activation  function $\\alpha_1$ and $\\alpha_2$ respectivly. We have that the loss function is given by \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{l} = \\alpha_2\\{\\alpha_1\\{x,\\theta_1\\},\\theta\\},\n",
    "\\end{equation*}\n",
    "where $\\theta_1$ and $\\theta_2$ is the covariates of each layer, which are to be learned. This means that we have values outputed from the first layer $z = \\alpha_1\\{x,\\theta_1\\}$, that will change when the parameters $\\theta_1$ are learned/changed. This means that the second layer, $ y = \\alpha_2\\{z,\\theta_2\\}$, will be affected by this distributional change in the outputs from the first layer and the network will learn slower than if the second layer wasn't affected by this change. Here we can apply batch normalization to the outputs of the first layer to fixate the inputs to the second layer such that it is not affected by the training of other layers. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Normalizing each layer using the whole dataset is very costly and is not differentiable everywhere. To account for this batch-normalization has been implemented using two similifications. The first one being that normalization is done along the different dimentions of the layers. Which means for the input normalization is happening for red, green and blue values, and within the network is would be normalized for the different filters. Which means that given a layer of dimension $d$, the input $\\mathbf{x} = (\\mathbf{x}^{(1)},\\mathbf{x}^{(2)},\\dots,\\mathbf{x}^{(d)})$ would be normalized by\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{x}} = \\frac{\\mathbf{x}^{(k)} - \\mathrm{E}[\\mathbf{x}^{(k)}]}{\\sqrt{\\mathrm{Var}[\\mathbf{x}^{(k)}]}}\n",
    "\\end{equation*}\n",
    "\n",
    "The batch-normalization must be a transformation that can represent the identity transform. This will account for the issue of normalization not being in the nonlinear domain of some activation functions (e.g. Sigmoid). To do this scale and shift parameters are introduced to the transformations that are learned along with the other model parameters. This results in the input to the layer in the neural network\n",
    "\\begin{equation*}\n",
    "\\mathbf{y}^{(k)} = \\mathbf{x}^{(k)}\\gamma^{(k)} + \\beta^{(k)},\n",
    "\\end{equation*}\n",
    "which means that the distribution of the input lie in the distribution $\\mathcal{N}[\\beta,\\gamma]$. Also of note here is that the transformation  would represent the identity transform if the $\\beta^{(k)} = \\mathrm{E}[\\mathbf{x}^{(k)}]$ and $\\gamma^{(k)} = \\mathrm{Var}[\\mathbf{x}^{(k)}]$.\n",
    "\n",
    "A second simplification is to use the mean and variance of the batch for normalization. This makes the normalization able to participate fully in the backpropagation. We split the data into mini-batches $\\mathcal{B}_i = \\{x_1^{(k)},\\dots,x_m\\}^{(k)}$ of size $m$. Then the batch-normalization transformation becomes\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathrm{BN}:x_{1\\dots m}^{(k)} \\rightarrow \\hat{x}_{1\\dots m}^{(k)} \\rightarrow y_{1\\dots m}^{(k)},\n",
    "\\end{equation*}\n",
    "\n",
    "which is summed up in the following algorithm which is the same algorithm included in the paper by <a href = \"https://arxiv.org/pdf/1502.03167v3.pdf\"> **Sergey Ioffe and Christian Szegedy**</a> .\n",
    "\n",
    "\\begin{equation*}\n",
    "\\boxed{\\begin{array}{ll}\n",
    "    \\textbf{Input:} & \\textrm{Values of x^{(k)} over a mini-batch:} \\enspace \\mathcal{B} = \\{x_{1,\\dots,m}\\}^{(k)};\\\\\n",
    "     & \\textrm{Parameters to be learned:} \\gamma^{(k)}, \\beta^{(k)} \\\\ \n",
    "     \\textbf{Output:} & \\{y_i^{(k)} = \\mathrm{BN}_{\\gamma^{(k)},\\beta^{(k)}}(x^{(k)}_i)\\} \\\\\n",
    "\\end{array}\\\\\n",
    "\\begin{array}{lr}\n",
    "    \\enspace \\mu_{\\mathcal{B}^{(k)}} = \\frac{1}{m}\\sum\\limits_{i=1}^m x_i^{(k)} & \\textrm{mini-batch mean} \\\\\n",
    "    \\enspace \\sigma_{\\mathcal{B}^{(k)}}^2 = \\frac{1}{m}\\sum\\limits_{i=1}^m (x_i^{(k)} - \\mu_{\\mathcal{B}^{(k)}})^2 & \\textrm{mini-batch variance}\\\\\n",
    "    \\enspace \\hat{x}_i^{(k)} = \\frac{x_i^{(k)} - \\mu_{mathcal{B}^{(k)}}}{\\sigma_{\\mathcal{B}^{(k)}}} & \\textrm{normalize} \\\\ \n",
    "    \\enspace y_i^{(k)} = \\gamma^{(k)} \\hat{x}_i^{(k)} + \\beta^{(k)} \\equiv \\mathrm{BN}_{\\gamma^{(k)},\\beta^{(k)}}(x_i^{(k)}) & \\textrm{scale and shift}\n",
    "\\end{array}}\\\\\n",
    "\\textbf{Algorithm 1:}\\textrm{ Batch Normalizing Transform, applied to} \\\\ \\textrm{activation } x \\textrm{ over a mini-batch.}\n",
    "\\end{equation*}\n",
    "\n",
    "The batch-normalization can be viewed as a sub-network within the bigger network. The $\\beta$ and $\\gamma$ parameters are learned through the training and the gradient of the loss $\\mathcal{l}$ of these parameters are found with the equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation*}\n",
    "\\begin{array}{rcl}\n",
    "    \\frac{\\partial\\mathcal{l}}{\\partial\\hat{x}_i} & = & \\frac{\\partial\\mathcal{l}}{\\partial y_i} \\gamma \\\\\n",
    "    \\frac{\\partial\\mathcal{l}}{\\partial\\sigma_\\mathcal{B}^2} & = & \\sum_{i = 1}^m \\frac{\\partial\\mathcal{l}}{\\partial\\hat{x}_i}\\frac{-1}{2}(\\sigma_\\mathcal{B}^2 + \\epsilon)^{-3/2} \\\\\n",
    "    \\frac{\\partial\\mathcal{l}}{\\partial\\mu_\\mathcal{B}} & = & \\left( \\sum_{i = 1}^m \\frac{\\partial\\mathcal{l}}{\\partial\\hat{x}_i} \\frac{-1}{\\sqrt{\\sigma_\\mathcal{B}^2 + \\epsilon}}\\right) + \\frac{\\partial\\mathcal{l}}{\\partial\\sigma_\\mathcal{B}^2} \\frac{\\sum_{i = 1}^m -2(x_i - \\mu_\\mathcal{B})}{m} \\\\\n",
    "    \\frac{\\partial\\mathcal{l}}{\\partial x_i} & = & \\frac{\\partial\\mathcal{l}}{\\partial\\hat{x}_i} \\frac{1}{\\sqrt{\\sigma_\\mathcal{B}^2 + \\epsilon}} + \\frac{\\partial\\mathcal{l}}{\\partial\\sigma_\\mathcal{B}^2}\\frac{2(x_i - \\mu_\\mathcal{B})}{m} + \\frac{\\partial\\mathcal{l}}{\\partial\\mu_\\mathcal{B}}\\frac{1}{m} \\\\\n",
    "    \\frac{\\partial\\mathcal{l}}{\\partial\\gamma} & = & \\sum_{i = 1}^m \\frac{\\partial\\mathcal{l}}{\\partial y_i} \\hat{x}_i \\\\\n",
    "    \\frac{\\partial\\mathcal{l}}{\\partial \\beta} & = & \\sum_{i = 1}^m \\frac{\\partial\\mathcal{l}}{\\partial y_i}.\n",
    "\\end{array}\n",
    "\\end{equation*}\n",
    "\n",
    "The joint distribution of the $\\hat{x}$ are assumed to change during training, but with the transformation the distributional change won't be as large as prior to the batch-normalization and thus result in faster training of the neural network. It is import to note that during training a running average and running variance is used to calculate the mini-batch statistics. This will stabalize the mini-batch statistics and the trainable parameters in the sub-network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['image.interpolation'] = 'nearest'\n",
    "mpl.rcParams['figure.figsize'] = 15, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 4\n",
    "n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(batch_size,img_size,last_it):\n",
    "    data_dir = '../numerical_examples/data/small/train/dogs/'\n",
    "    data_files = os.listdir(data_dir)\n",
    "    array = np.array(\n",
    "        [\n",
    "            np.array(Image.open(f'{data_dir}/{data_files[i]}').resize((img_size, img_size), Image.ANTIALIAS))\n",
    "            for i\n",
    "            in range(last_it,batch_size+last_it)\n",
    "        ]\n",
    "    )\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalization2d(array,gamma,beta,eps=1e-5):\n",
    "    assert array.ndim == 4\n",
    "    mean = array.mean(axis=(0,1,2))\n",
    "    std = array.std(axis=(0,1,2))\n",
    "    array = (array - mean)/np.sqrt(std**2 + eps)\n",
    "    array = array*gamma + beta\n",
    "    return array\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(array):\n",
    "    img = np.hstack(array)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.pause(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_flow(img_size,batch_size,n):\n",
    "    num_batches = n//batch_size\n",
    "    last_batch_num = 0\n",
    "    gamma = 127.5\n",
    "    beta = 255\n",
    "    for i in range(num_batches):\n",
    "        batch = load_batch(batch_size,img_size,last_batch_num)\n",
    "        normalized_batch = batch_normalization2d(batch,gamma,beta)\n",
    "        visualize_batch(normalized_batch)\n",
    "        last_batch_num += batch_size\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABiCAYAAADz0wB7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABeklEQVR4nO3asQ2AMAwAQYKy/8phAhTRPEXuWjeuXi481loXAI377wUATiK6ACHRBQiJLkBIdAFCogsQmpu5fzKA78bbwKULEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoTmZj6SLQAO4dIFCIkuQEh0AUKiCxASXYCQ6AKEHjBPBMY3xC/pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABiCAYAAADz0wB7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADVElEQVR4nO3d0VLbMBBAUbnDj8KH0U91nzwYQ2JMpdVKPmemk4dMgxuam0Ux8rKuawEgxp/eBwBwJ6ILEEh0AQKJLkAg0QUIJLoAgV5O7h/jfLKljHKkwD0sj+6YZ9J9+E8EyGP86IotMJB60W0Zv7cn9626C4xjOfk14H4rpVfWaffVtbYLnAj4GGjANV3xBBpZy/dVjPipOW90r9gH2loD8AO95ro5olvKxzP46C0M4EREiOeJLsAA5onutjK+vwVIZp7ofhdc4QWSyR3dq9HcB3ctzoAA0skd3e+iuZTPMT6GWWyBxHJHd+84wR7j++zvACRxtstYHsdzcX8yzZp4gWTGmHTfil/1BaYwRnT/VniMZ5vmAATJu+ENwLgG3PAGYEL5olt7GcAZDEAiuc5eaLHJpQUSIJFck65AApPLFV2AyYkuQKC80W3xAZgP1YDO8ka3xfquNWOgs7zR3Ws9oZqAgSBjRLf1lSBMwECQMaIbcJF6gAhjRFdwgUmMEd3NUr5u89hbpmMB0muzy1iN5YD9Y2RdXsh6XEBvA+4ytg/ua8k5UQoucFHd6O6vY1bzYbdNzLfrotmQHBhU/eWF2j9yP5twa30dywRAXYHLC7XOqY1cThBcIEibNd0aEVsPt0evFb4GQLA20d2m1Bprr8erAG9/3is89tnXA6gs74Upl4+bte+RAFz1cHzLdbmevfXTDcAU8p6n25tlBqAB0X3EiD0+b5wklDe6GV4wGY6B3/PGSUJ5o5vhBdN6H1/a8/0jmbzRzSJD/Pk93z+SEV2AQKILEEh0AQKJLkAg0QUIJLoAgUQXIJDoAgQSXYBAogsQSHQBAokuQCDRBQgkugCB7hdd+6sCHd0vuvZXBTq6X3QBOhJdgECiCxBIdAECiS5AINEFCHT76DptF4h0++g6bReIVD+6o42Ob70PALiTZV2fznoGQYDrHo6ft19eKKWUZbTpfDaef25EdEspz4d9mvP8cyOiyzisvzMB0d14QVe1LKX+c/pe+fGgAx+kcc1S/K+Acz5IoxLBhf8iugCV/OREHNEFqGQt5+EVXYBAogtQ0dnHHqILEEh0AQKJLkCgl5P7bUUCUJFJFyCQ6AIEEl2AQKILEEh0AQKJLkCgfxdMciVL8Dn6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABiCAYAAADz0wB7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABeklEQVR4nO3asQ2AMAwAQYKy/8phAhTRPEXuWjeuXi481loXAI377wUATiK6ACHRBQiJLkBIdAFCogsQmpu5fzKA78bbwKULEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoTmZj6SLQAO4dIFCIkuQEh0AUKiCxASXYCQ6AKEHjBPBMY3xC/pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABiCAYAAADz0wB7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABeklEQVR4nO3asQ2AMAwAQYKy/8phAhTRPEXuWjeuXi481loXAI377wUATiK6ACHRBQiJLkBIdAFCogsQmpu5fzKA78bbwKULEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoTmZj6SLQAO4dIFCIkuQEh0AUKiCxASXYCQ6AKEHjBPBMY3xC/pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABiCAYAAADz0wB7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABeklEQVR4nO3asQ2AMAwAQYKy/8phAhTRPEXuWjeuXi481loXAI377wUATiK6ACHRBQiJLkBIdAFCogsQmpu5fzKA78bbwKULEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoTmZj6SLQAO4dIFCIkuQEh0AUKiCxASXYCQ6AKEHjBPBMY3xC/pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize_flow(img_size,batch_size,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
