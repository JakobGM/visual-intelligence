The development of Mask R-CNN is an interesting case study for how existing model architectures can be expanded in order to solve entirely new problems.
Faster R-CNN had cutting edge performance on image classification and localization tasks when it was published in 2015.
Researchers at Facebook managed to modify this model architecture in order to achieve first of class performance on segmentation problems as well.

What makes Faster R-CNN so powerful in the first place?
The crux of it lies in the "Region Proposal Network" which identifies regions of high interest for the given classification task.
These regions are transformed into a consistent resolution using the so-called RoIPool algorithm, and these are subsequently classified.
Now the question asks itself, can we attach something to this model architecture in order to predict segmentation masks as well?

The idea is to attach a parallel and completely independent mask branch to the RoIPool output.
Unlike the classification branch, which utilizes a fully connected multilayer perceptron, the mask branch is implemented with a fully convolutional neural network instead.

Unfortunately, this approach causes an issue to arise.
The region of interest pooling, which extracts images of consistent resolution from the regions of interest, introduces tiny pixel misalignments.
While this is no problem for bounding box regression and classification, it has detrimental impact for pixel-wise segmentation tasks where high precision is key.
This needs to be fixed.

The solution is to replace RoIPool with a new pooling method, which has become known as "RoIAlign".
RoIAlign uses bilinear interpolation in order to realign the new pixels correctly.
This results in a correct one-to-one mapping between the region of interest, and the resulting feature map.

The first step in improving this model is therefore to replace RoIPool with RoIAlign.

This modification proved to be a great improvement for the overall performance of the resulting network.
The average precision increased by over three percentage points when using stride of size 16.
When using larger strides of 32, where the pixel misalignments become more significant, the average precision increased by almost six percentage points.

Another key insight by the research team at Facebook was to reuse the work performed by the classification branch in order to create class-specific masks.
The mask branch predicts one independent mask for each class label, without inter-class competition, and then finally decides which one to use by asking the classification branch.
This causes the architecture to become even more uncoupled.

Independent mask predictions can now be generated by using the single-class sigmoid activation function instead of the multi-class softmax activation function.
The mask branch can focus on predicting suitable masks independently of each other, without the need for comparing the probabilities between these.
The average precision of the network increases with over five percentage points as a result.

We can now compare Mask R-CNN with the FCIS model architecture from the same time period.
The FCIS model performs object classification, bounding box regression, and segmentation, using only a single channel, and does therefore not portray the same uncoupled behavior as Mask R-CNN.
While FCIS portrays difficulties with overlapping objects, due to class competition along the object borders, Mask R-CNN does not portray the same issue.
